# Competitor Intelligence Dashboard

## Overview

This is a comprehensive Streamlit web application that monitors competitor changelog updates, generates AI-powered insights, and tracks competitive momentum across the product landscape. The system scrapes competitor websites, uses OpenAI GPT-4 to analyze content, tracks visual UI changes via screenshots, and delivers actionable intelligence through multiple channels including Slack notifications.

The application is designed as a competitive intelligence tool for product teams, sales teams, and design teams to stay informed about competitor product updates and market trends.

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

The application follows a modular microservices-inspired architecture with clear separation of concerns:

**Frontend Layer**: Streamlit-based web dashboard for user interaction and data visualization
**Scraping Layer**: Web content extraction using trafilatura and requests
**AI Processing Layer**: OpenAI GPT-4 integration for content analysis and summarization  
**Computer Vision Layer**: Playwright + OpenCV for screenshot capture and visual diff detection
**Notification Layer**: Slack webhook integration for automated alerts
**Data Persistence Layer**: PostgreSQL database with SQLAlchemy ORM for robust data storage and historical tracking

The architecture supports both interactive usage through the web interface and automated batch processing for scheduled competitor monitoring.

## Key Components

### Main Application (app.py)
- **Purpose**: Streamlit web application entry point and UI orchestration
- **Features**: Dashboard layout, session state management, user interactions
- **Technology**: Streamlit with wide layout and sidebar controls

### Web Scraper (scraper.py)
- **Purpose**: Extracts changelog content from competitor websites
- **Technology**: Uses trafilatura library for robust content extraction
- **Features**: Rate limiting (1 second between requests), platform-specific handling, session management
- **Supported Platforms**: Generic websites, Notion, Linear, and other changelog formats

### AI Summarizer (summarizer.py)
- **Purpose**: Converts raw changelog content into structured, actionable summaries
- **Technology**: OpenAI GPT-4 API integration
- **Output Format**: JSON-structured summaries with bullet points, strategic insights, and confidence levels
- **Rate Limiting**: 1 second between API calls to respect OpenAI usage limits

### Screenshot Comparer (diff_checker.py)
- **Purpose**: Tracks visual UI changes across competitor websites
- **Technology**: Playwright for screenshot capture, OpenCV for image difference detection
- **Features**: Automated screenshot capture, pixel-level difference detection, change highlighting
- **Storage**: Local screenshot directory with timestamp-based organization

### Dashboard Components (dashboard.py)
- **Purpose**: Data visualization and report formatting utilities
- **Features**: Momentum scoring charts, trend analysis, persona-specific views (PM/Sales/Design)
- **Technology**: Plotly for interactive charts, Streamlit for layout components

### Slack Notifier (notifier.py)
- **Purpose**: Automated delivery of competitor intelligence updates
- **Technology**: Slack webhook API integration
- **Features**: Formatted digest messages, momentum leaderboards, strategic alerts

### Configuration Management (config.py)
- **Purpose**: Centralized competitor definitions and application settings
- **Coverage**: Pre-configured competitors include Linear, Notion, Airtable, Figma, Slack, Discord
- **Structure**: Each competitor includes URL, platform type, description, homepage URL, and category

### Database Management (database.py)
- **Purpose**: PostgreSQL data persistence and historical tracking
- **Features**: SQLAlchemy ORM, competitor analysis storage, trend tracking, screenshot metadata
- **Tables**: competitor_analyses, trend_analyses, screenshot_comparisons, competitor_configs
- **Functionality**: Automatic table creation, data migration, historical data retrieval

### Utilities (utils.py)
- **Purpose**: File handling and helper functions (legacy file-based storage as backup)
- **Features**: JSON serialization, historical data loading, screenshot management
- **Storage**: File-based persistence in organized directory structure

## Data Flow

1. **Configuration Loading**: Application loads competitor configurations and API credentials from environment variables
2. **User Input Processing**: Streamlit interface accepts user selections for competitors to monitor
3. **Content Scraping**: Web scraper extracts changelog content from competitor URLs with rate limiting
4. **AI Analysis**: OpenAI GPT-4 processes raw content into structured summaries with strategic insights
5. **Momentum Scoring**: System calculates competitive momentum scores based on update frequency and impact (AI=3, Feature=2, UI=1)
6. **Trend Analysis**: Cross-competitor analysis identifies dominant themes and market trends
7. **Screenshot Capture**: Playwright captures UI screenshots for visual change detection
8. **Visual Diff Processing**: OpenCV compares screenshots to identify UI changes
9. **Database Persistence**: PostgreSQL stores analysis results, trends, and metadata for historical tracking
10. **Report Generation**: Multiple persona-specific views (PM, Sales, Design) with tailored insights
11. **Notification Delivery**: Slack integration delivers formatted digest reports

## External Dependencies

### Core Libraries
- **Streamlit**: Web application framework for dashboard interface
- **OpenAI**: GPT-4 API for AI-powered content analysis and summarization
- **Playwright**: Browser automation for screenshot capture (optional dependency with graceful fallback)
- **OpenCV**: Computer vision library for image difference detection
- **Trafilatura**: Web scraping library optimized for text extraction
- **Plotly**: Interactive charting library for data visualization
- **Requests**: HTTP client for web scraping and API communication

### External Services
- **OpenAI API**: Requires API key for GPT-4 content analysis
- **Slack Webhook**: Optional integration for automated notifications
- **Target Websites**: Monitors competitor sites including Linear, Notion, Airtable, Figma, Slack, Discord

### Environment Configuration
- `OPENAI_API_KEY`: Required for AI summarization features
- `SLACK_WEBHOOK_URL`: Optional for Slack notification delivery

## Deployment Strategy

The application is designed for containerized deployment with the following considerations:

**Development Environment**: Local Streamlit server with file-based persistence
**Production Environment**: Cloud deployment (Replit, Heroku, or similar) with environment variable configuration
**Data Storage**: File-based JSON storage with organized directory structure (data/, screenshots/)
**Scheduling**: Manual execution through web interface or external cron scheduling for automated monitoring
**Scaling**: Stateless design allows for horizontal scaling with shared file storage
**Error Handling**: Graceful degradation when optional dependencies (Playwright) are unavailable

The system includes comprehensive logging and error handling to ensure reliable operation in production environments. Rate limiting and respectful scraping practices ensure compliance with target website terms of service.